---
title: "Homework 6"
author: "Alice Tivarovsky"
date: "11/16/2019"
output: html_document
---

Setup code: 

```{r setup}
library(tidyverse)
library(modelr)
library(MASS)
library(patchwork)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))

```

## Problem 1

### Data tidying and analysis

Loading and tidying birthweight dataset: 

```{r}
bwt_data = 
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    babysex = as_factor(babysex),
    frace = as_factor(frace),
    malform = as_factor(malform), 
    mrace = as_factor(mrace)
  ) 

```
The resulting dataset contains 4342 observations across 20 variables. Numerical  variables were converted to categorical variables based on the data dictionary using as_factor. 

Next, we check for missing values using purrr: 
```{r}
bwt_data %>% 
  map_df(~sum(is.na(.)))
```

We confirm there are no missing values in the dataset. 

### Model-building using AIC

Next, we use stepwise AIC model-building analysis, which evaluates goodness-of-fit against model simplicity in a stepwise fashion to propose a linear regression model: 

```{r}
full_model = lm(bwt ~. , data = bwt_data)

stepAIC(full_model, direction = "both")
  
```


AIC analysis concludes that variables babysex, bhead, blength, delwt, fincome, gaweeks, mheight, mrace, parity, ppwt, and smoken are valuable predictors in the model. We use this model to fit a regression line: 

```{r}
aic_model = 
  bwt_data %>%  
  lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .) 

```

The resulting model has a strong R-squared of 71.81% and a significant global F-test (p-value = 0). 

Next we plot the residuals versus the fitted values. 

```{r}

bwt_data %>% 
  add_residuals(aic_model) %>% 
  add_predictions(aic_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
    title = "Residual Plot for Proposed Model",
    x = "Predicted Value", 
    y = "Residual"
  )

```

The residual plot resulting from the proposed model indicates potential problems with the model, particularly at values below 1500 grams, where the residuals appear to follow a non-random pattern. 

### Cross-Validation

Next we use cross-validation methods to compare the proposed model to two other models. 

First we create the testing and training datasets: 

```{r}
cv_bwt = 
  crossv_mc(bwt_data, 100) 
```

Next, we use the datasets to fit two more candidate models: one that uses only the main effects of length at birth and gestational age, and one using head circumference, length, sex, and all associated interactions. We create a new dataframe using the computed prediction errors from the three candidate models. 

```{r}

cv_bwt = 
  cv_bwt %>% 
  mutate(model_a = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_b = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + blength*babysex*bhead, data = .x)),
         aic_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .))
  ) %>% 
  mutate(rmse_a = map2_dbl(model_a, test, ~rmse(model = .x, data = .y)),
         rmse_b = map2_dbl(model_b, test, ~rmse(model = .x, data = .y)),
         rmse_aic = map2_dbl(aic_model, test, ~rmse(model = .x, data = .y))) 
         
```  


Finally, we generate comparison plots using rmse: 

```{r}
error_plot = 
  cv_bwt %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Plot of rmse for candidate models",
    x = "Model", 
    y = "rmse"
  )

error_plot

```

Based on the rmse plot, the original model built from AIC analysis is the best model since, overall, it produces the smallest prediction errors. 

# Problem 2

This problem will be completed using data from the rnoaa package. We load and tidy the data: 

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(c("USW00094728", "USC00519397", "USS0023B17S"),
                      var = c("PRCP", "TMIN", "TMAX"), 
                      date_min = "2017-01-01",
                      date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY", 
                      USC00519397 = "Waikiki_HA",
                      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())
weather_df
```

Using the `weather_df` dataset, we draw 5000 bootstrap samples and fit a linear regression with `tmax` as the response and `tmin` as the predictor. We are interested in the model r-squared and the value of log(beta_0 * beta_1). 

Here, we draw the bootstrap samples and create a dataframe containing the values of interest.

```{r}
boot_weather =
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy), 
    glance = map(models, broom::glance)) %>% 
  dplyr::select(results, glance) %>% 
  unnest(results, glance) %>% 
  janitor::clean_names() %>% 
  dplyr::select(term,estimate, r_squared) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate)  %>% 
  janitor::clean_names() %>% 
  mutate(log_est = log(intercept * tmin)) 
  
```

Next we plot the distributions of r-squared and log(beta_0 * beta_1). 

```{r}
r_squared_plot = 
  boot_weather %>% 
  ggplot(aes(x = r_squared)) +
  geom_density() +
  labs(
    title = "R Squared Plot", 
    x = "r-squared", 
    y = "Density"
  )

log_est_plot = 
  boot_weather %>% 
  ggplot(aes(x = log_est)) +
  geom_density() + 
  labs(
    title = "Plot of log(beta_0 * beta_1)", 
    x = "log(beta_0 * beta_1", 
    y = "Density"
  )

(r_squared_plot + log_est_plot)
```
<br>
Both values are normally distributed with small "shoulders" on the left side, most likely due to the influence of outliers. 

Finally, we compute 2.5% and 97.5% quantiles to provide a 95% confidence interval for `r_squared` and `log_est`. 

```{r}

pull(boot_weather, r_squared) %>% quantile(c(0.025, .975))

pull(boot_weather, log_est) %>% quantile(c(0.025, .975))
```

Based on the bootstrap sample, the 95% confidence interval for r-squared is (0.9368292, 0.9487296) and the 95% confidence interval for log(beta_0 * beta_1) is (2.017156, 2.065878). 
<br><br>
